{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COL_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLength</th>\n      <th>SepalWidth</th>\n      <th>PetalLength</th>\n      <th>PetalWidth</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.0</td>\n      <td>2.9</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.8</td>\n      <td>3.4</td>\n      <td>1.9</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6.1</td>\n      <td>2.8</td>\n      <td>4.7</td>\n      <td>1.2</td>\n      <td>Iris-versicolor</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.0</td>\n      <td>3.2</td>\n      <td>4.7</td>\n      <td>1.4</td>\n      <td>Iris-versicolor</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   SepalLength  SepalWidth  PetalLength  PetalWidth          Species\n0          5.9         3.0          5.1         1.8   Iris-virginica\n1          6.0         2.9          4.5         1.5  Iris-versicolor\n2          4.8         3.4          1.9         0.2      Iris-setosa\n3          6.1         2.8          4.7         1.2  Iris-versicolor\n4          7.0         3.2          4.7         1.4  Iris-versicolor"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./iris.data.csv', names=CSV_COL_NAMES, header=0)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[:119]\n",
    "test_data = df[119:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data[train_data.columns[-1]]\n",
    "train_data = train_data.drop(train_data.columns[-1], axis=1)\n",
    "\n",
    "test_label = test_data[test_data.columns[-1]]\n",
    "test_data = test_data.drop(test_data.columns[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_dict = {col: {'mean':df[col].mean(), 'std': df[col].std()} for col in train_data.columns}\n",
    "\n",
    "def sl_normalize(x):\n",
    "    return (x - mean_std_dict['SepalLength']['mean'])/mean_std_dict['SepalLength']['std']\n",
    "\n",
    "def sw_normalize(x):\n",
    "    return (x - mean_std_dict['SepalWidth']['mean'])/mean_std_dict['SepalWidth']['std']\n",
    "\n",
    "def pl_normalize(x):\n",
    "    return (x - mean_std_dict['PetalLength']['mean'])/mean_std_dict['PetalLength']['std']\n",
    "\n",
    "def pw_normalize(x):\n",
    "    return (x - mean_std_dict['PetalWidth']['mean'])/mean_std_dict['PetalWidth']['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_cols = []\n",
    "my_feature_cols.append(tf.feature_column.numeric_column(key=CSV_COL_NAMES[0], normalizer_fn=sl_normalize))\n",
    "my_feature_cols.append(tf.feature_column.numeric_column(key=CSV_COL_NAMES[1], normalizer_fn=sw_normalize))\n",
    "my_feature_cols.append(tf.feature_column.numeric_column(key=CSV_COL_NAMES[2], normalizer_fn=pl_normalize))\n",
    "my_feature_cols.append(tf.feature_column.numeric_column(key=CSV_COL_NAMES[3], normalizer_fn=pw_normalize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "\n",
    "    def __init__(self, feature_cols):\n",
    "        super(Model, self).__init__()\n",
    "        self.feature_cols = feature_cols\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        net = tf.feature_column.input_layer(feature_columns=self.feature_cols, features=input)\n",
    "        net = tf.layers.dense(inputs=net, units=10, activation=tf.nn.relu, name='layer_1')\n",
    "        net = tf.layers.dense(inputs=net, units=10, activation=tf.nn.relu, name='layer_2')\n",
    "        net = tf.layers.dense(inputs=net, units=3, activation=None, name='logits')\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "\n",
    "    model = Model(my_feature_cols)\n",
    "    global_steps = tf.train.get_global_step()\n",
    "\n",
    "    logits = model(features)\n",
    "    logits = tf.cast(logits, tf.float64)\n",
    "    pred_logits = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
    "    probs = tf.nn.softmax(logits)\n",
    "\n",
    "    predictions = {\n",
    "        'pred_logits': pred_logits,\n",
    "        'probabilities': probs\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(predictions=predictions, mode=mode)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        error = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits, scope='loss')\n",
    "        tf.summary.scalar('loss', error)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.metrics.accuracy(labels=labels, predictions=pred_logits, name='acc')\n",
    "        tf.summary.scalar('accuracy',accuracy[1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=error, eval_metric_ops={\n",
    "            'accuracy/accuracy':accuracy\n",
    "        }, evaluation_hooks=None)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(error, global_step=global_steps)\n",
    "    train_hooks_list = []\n",
    "    train_tensor_log ={'accuracy': accuracy[1], 'loss':error, 'global_steps':global_steps}\n",
    "    train_hooks_list.append(tf.train.LoggingTensorHook(tensors=train_tensor_log, every_n_iter=100))\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=error, train_op=optimizer, training_hooks=train_hooks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['Iris-virginica', 'Iris-versicolor', 'Iris-setosa']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_nor(x):\n",
    "    tmp = { v:i for i,v in enumerate(df['Species'].unique().tolist())}\n",
    "    return x.apply(lambda x : tmp[x])\n",
    "\n",
    "def get_input_fn(features, labels, batch_size=32, shuffle=True, num_epoch=1000):\n",
    "    \n",
    "    def input_fn():\n",
    "        if labels is not None:\n",
    "            dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels_nor(labels)))\n",
    "        else:\n",
    "            dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(1000)\n",
    "        dataset = dataset.batch(batch_size).repeat(num_epoch)\n",
    "        return dataset\n",
    "    return input_fn\n",
    "\n",
    "train_input_fn = get_input_fn(train_data, train_label)\n",
    "eval_input_fn = get_input_fn(test_data, test_label, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': './Model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025F03167160>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
    }
   ],
   "source": [
    "classifier = tf.estimator.Estimator(model_fn=model_fn, model_dir='./Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\nINFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:205: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\nInstructions for updating:\nThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\nWARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:2115: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\nInstructions for updating:\nThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\nWARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:206: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\nInstructions for updating:\nThe old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\nWARNING:tensorflow:From <ipython-input-8-c8059a18dba4>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse keras.layers.dense instead.\nWARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Saving checkpoints for 0 into ./Model\\model.ckpt.\nINFO:tensorflow:loss = 1.232041597366333, step = 0\nINFO:tensorflow:accuracy = 0.0625, global_steps = 0, loss = 1.232041597366333\nINFO:tensorflow:global_step/sec: 135.166\nINFO:tensorflow:loss = 0.8045778274536133, step = 100 (0.741 sec)\nINFO:tensorflow:accuracy = 0.375, global_steps = 100, loss = 0.8045778274536133 (0.739 sec)\nINFO:tensorflow:global_step/sec: 139.067\nINFO:tensorflow:loss = 0.545066773891449, step = 200 (0.723 sec)\nINFO:tensorflow:accuracy = 0.5, global_steps = 200, loss = 0.545066773891449 (0.726 sec)\nINFO:tensorflow:global_step/sec: 148.106\nINFO:tensorflow:loss = 0.27636849880218506, step = 300 (0.672 sec)\nINFO:tensorflow:accuracy = 0.6171875, global_steps = 300, loss = 0.27636849880218506 (0.670 sec)\nINFO:tensorflow:global_step/sec: 134.588\nINFO:tensorflow:loss = 0.1284443438053131, step = 400 (0.746 sec)\nINFO:tensorflow:accuracy = 0.69375, global_steps = 400, loss = 0.1284443438053131 (0.750 sec)\nINFO:tensorflow:global_step/sec: 136.782\nINFO:tensorflow:loss = 0.116392120718956, step = 500 (0.732 sec)\nINFO:tensorflow:accuracy = 0.7447917, global_steps = 500, loss = 0.116392120718956 (0.730 sec)\nINFO:tensorflow:global_step/sec: 147.03\nINFO:tensorflow:loss = 0.11553218960762024, step = 600 (0.673 sec)\nINFO:tensorflow:accuracy = 0.77678573, global_steps = 600, loss = 0.11553218960762024 (0.672 sec)\nINFO:tensorflow:global_step/sec: 165.728\nINFO:tensorflow:loss = 0.07117585837841034, step = 700 (0.606 sec)\nINFO:tensorflow:accuracy = 0.80078125, global_steps = 700, loss = 0.07117585837841034 (0.606 sec)\nINFO:tensorflow:global_step/sec: 138.303\nINFO:tensorflow:loss = 0.034668080508708954, step = 800 (0.723 sec)\nINFO:tensorflow:accuracy = 0.8229167, global_steps = 800, loss = 0.034668080508708954 (0.722 sec)\nINFO:tensorflow:global_step/sec: 137.73\nINFO:tensorflow:loss = 0.10474150627851486, step = 900 (0.727 sec)\nINFO:tensorflow:accuracy = 0.8375, global_steps = 900, loss = 0.10474150627851486 (0.727 sec)\nINFO:tensorflow:global_step/sec: 150.552\nINFO:tensorflow:loss = 0.02363080158829689, step = 1000 (0.670 sec)\nINFO:tensorflow:accuracy = 0.85227275, global_steps = 1000, loss = 0.02363080158829689 (0.671 sec)\nINFO:tensorflow:global_step/sec: 146.369\nINFO:tensorflow:loss = 0.043748971074819565, step = 1100 (0.679 sec)\nINFO:tensorflow:accuracy = 0.8645833, global_steps = 1100, loss = 0.043748971074819565 (0.681 sec)\nINFO:tensorflow:global_step/sec: 151.013\nINFO:tensorflow:loss = 0.00908383447676897, step = 1200 (0.657 sec)\nINFO:tensorflow:accuracy = 0.875, global_steps = 1200, loss = 0.00908383447676897 (0.654 sec)\nINFO:tensorflow:global_step/sec: 140.038\nINFO:tensorflow:loss = 0.01470964029431343, step = 1300 (0.714 sec)\nINFO:tensorflow:accuracy = 0.8839286, global_steps = 1300, loss = 0.01470964029431343 (0.714 sec)\nINFO:tensorflow:global_step/sec: 145.316\nINFO:tensorflow:loss = 0.010178927332162857, step = 1400 (0.690 sec)\nINFO:tensorflow:accuracy = 0.89166665, global_steps = 1400, loss = 0.010178927332162857 (0.699 sec)\nINFO:tensorflow:global_step/sec: 140.234\nINFO:tensorflow:loss = 0.011666973121464252, step = 1500 (0.711 sec)\nINFO:tensorflow:accuracy = 0.8984375, global_steps = 1500, loss = 0.011666973121464252 (0.702 sec)\nINFO:tensorflow:global_step/sec: 147.228\nINFO:tensorflow:loss = 0.01826949045062065, step = 1600 (0.683 sec)\nINFO:tensorflow:accuracy = 0.9044118, global_steps = 1600, loss = 0.01826949045062065 (0.683 sec)\nINFO:tensorflow:global_step/sec: 140.205\nINFO:tensorflow:loss = 0.0732043907046318, step = 1700 (0.712 sec)\nINFO:tensorflow:accuracy = 0.9079861, global_steps = 1700, loss = 0.0732043907046318 (0.714 sec)\nINFO:tensorflow:global_step/sec: 142.223\nINFO:tensorflow:loss = 0.03252965584397316, step = 1800 (0.702 sec)\nINFO:tensorflow:accuracy = 0.9128289, global_steps = 1800, loss = 0.03252965584397316 (0.699 sec)\nINFO:tensorflow:global_step/sec: 149.246\nINFO:tensorflow:loss = 0.004632001277059317, step = 1900 (0.671 sec)\nINFO:tensorflow:accuracy = 0.9171875, global_steps = 1900, loss = 0.004632001277059317 (0.676 sec)\nINFO:tensorflow:global_step/sec: 153.553\nINFO:tensorflow:loss = 0.010446660220623016, step = 2000 (0.650 sec)\nINFO:tensorflow:accuracy = 0.92113096, global_steps = 2000, loss = 0.010446660220623016 (0.647 sec)\nINFO:tensorflow:global_step/sec: 263.169\nINFO:tensorflow:loss = 0.07104167342185974, step = 2100 (0.379 sec)\nINFO:tensorflow:accuracy = 0.92329544, global_steps = 2100, loss = 0.07104167342185974 (0.376 sec)\nINFO:tensorflow:global_step/sec: 259.761\nINFO:tensorflow:loss = 0.015558901242911816, step = 2200 (0.385 sec)\nINFO:tensorflow:accuracy = 0.92663044, global_steps = 2200, loss = 0.015558901242911816 (0.385 sec)\nINFO:tensorflow:global_step/sec: 150.778\nINFO:tensorflow:loss = 0.06639392673969269, step = 2300 (0.667 sec)\nINFO:tensorflow:accuracy = 0.92838544, global_steps = 2300, loss = 0.06639392673969269 (0.676 sec)\nINFO:tensorflow:global_step/sec: 140.039\nINFO:tensorflow:loss = 0.013325873762369156, step = 2400 (0.712 sec)\nINFO:tensorflow:accuracy = 0.93125, global_steps = 2400, loss = 0.013325873762369156 (0.704 sec)\nINFO:tensorflow:global_step/sec: 153.549\nINFO:tensorflow:loss = 0.054512929171323776, step = 2500 (0.650 sec)\nINFO:tensorflow:accuracy = 0.9326923, global_steps = 2500, loss = 0.054512929171323776 (0.649 sec)\nINFO:tensorflow:global_step/sec: 157.654\nINFO:tensorflow:loss = 0.030736833810806274, step = 2600 (0.634 sec)\nINFO:tensorflow:accuracy = 0.9351852, global_steps = 2600, loss = 0.030736833810806274 (0.634 sec)\nINFO:tensorflow:global_step/sec: 142.628\nINFO:tensorflow:loss = 0.006621584761887789, step = 2700 (0.700 sec)\nINFO:tensorflow:accuracy = 0.9375, global_steps = 2700, loss = 0.006621584761887789 (0.701 sec)\nINFO:tensorflow:global_step/sec: 132.105\nINFO:tensorflow:loss = 0.005319880321621895, step = 2800 (0.757 sec)\nINFO:tensorflow:accuracy = 0.9396552, global_steps = 2800, loss = 0.005319880321621895 (0.757 sec)\nINFO:tensorflow:global_step/sec: 148.986\nINFO:tensorflow:loss = 0.01260510552674532, step = 2900 (0.671 sec)\nINFO:tensorflow:accuracy = 0.94166666, global_steps = 2900, loss = 0.01260510552674532 (0.671 sec)\nINFO:tensorflow:global_step/sec: 131.069\nINFO:tensorflow:loss = 0.029788004234433174, step = 3000 (0.764 sec)\nINFO:tensorflow:accuracy = 0.9435484, global_steps = 3000, loss = 0.029788004234433174 (0.765 sec)\nINFO:tensorflow:global_step/sec: 213.336\nINFO:tensorflow:loss = 0.030045706778764725, step = 3100 (0.468 sec)\nINFO:tensorflow:accuracy = 0.9453125, global_steps = 3100, loss = 0.030045706778764725 (0.467 sec)\nINFO:tensorflow:global_step/sec: 249.421\nINFO:tensorflow:loss = 0.049178242683410645, step = 3200 (0.403 sec)\nINFO:tensorflow:accuracy = 0.94602275, global_steps = 3200, loss = 0.049178242683410645 (0.403 sec)\nINFO:tensorflow:global_step/sec: 148.545\nINFO:tensorflow:loss = 0.01011655107140541, step = 3300 (0.676 sec)\nINFO:tensorflow:accuracy = 0.9476103, global_steps = 3300, loss = 0.01011655107140541 (0.676 sec)\nINFO:tensorflow:global_step/sec: 148.106\nINFO:tensorflow:loss = 0.028724998235702515, step = 3400 (0.671 sec)\nINFO:tensorflow:accuracy = 0.9482143, global_steps = 3400, loss = 0.028724998235702515 (0.670 sec)\nINFO:tensorflow:global_step/sec: 150.101\nINFO:tensorflow:loss = 0.021906085312366486, step = 3500 (0.668 sec)\nINFO:tensorflow:accuracy = 0.9496528, global_steps = 3500, loss = 0.021906085312366486 (0.668 sec)\nINFO:tensorflow:global_step/sec: 138.875\nINFO:tensorflow:loss = 0.033512312918901443, step = 3600 (0.719 sec)\nINFO:tensorflow:accuracy = 0.9501689, global_steps = 3600, loss = 0.033512312918901443 (0.726 sec)\nINFO:tensorflow:global_step/sec: 136.604\nINFO:tensorflow:loss = 0.013107867911458015, step = 3700 (0.734 sec)\nINFO:tensorflow:accuracy = 0.95148027, global_steps = 3700, loss = 0.013107867911458015 (0.732 sec)\nINFO:tensorflow:global_step/sec: 154.258\nINFO:tensorflow:loss = 0.005252228584140539, step = 3800 (0.647 sec)\nINFO:tensorflow:accuracy = 0.95272434, global_steps = 3800, loss = 0.005252228584140539 (0.641 sec)\nINFO:tensorflow:global_step/sec: 147.432\nINFO:tensorflow:loss = 0.004565131384879351, step = 3900 (0.679 sec)\nINFO:tensorflow:accuracy = 0.95390624, global_steps = 3900, loss = 0.004565131384879351 (0.678 sec)\nINFO:tensorflow:Saving checkpoints for 4000 into ./Model\\model.ckpt.\nINFO:tensorflow:Loss for final step: 0.013315935619175434.\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2019-12-29T16:53:30Z\nINFO:tensorflow:Graph was finalized.\nWARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflowEnv\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to check for files with this prefix.\nINFO:tensorflow:Restoring parameters from ./Model\\model.ckpt-4000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Finished evaluation at 2019-12-29-16:53:33\nINFO:tensorflow:Saving dict for global step 4000: accuracy/accuracy = 0.93333334, global_step = 4000, loss = 0.14747456\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: ./Model\\model.ckpt-4000\n"
    }
   ],
   "source": [
    "classifier.train(train_input_fn)\n",
    "metric = classifier.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " predict_ = {\n",
    "     'SepalLength': [5.1, 5.9, 6.9],\n",
    "     'SepalWidth': [3.3, 3.0, 3.1],\n",
    "     'PetalLength': [1.7, 4.2, 5.4],\n",
    "     'PetalWidth': [0.5, 1.5, 2.1]\n",
    " }\n",
    " df_test = pd.DataFrame(predict_)\n",
    " df_test_fn = get_input_fn(df_test, None, shuffle=False, num_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(df_test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "INFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from ./Model\\model.ckpt-4000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n"
    },
    {
     "data": {
      "text/plain": "[{'pred_logits': 2,\n  'probabilities': array([9.69825594e-06, 6.15165768e-05, 9.99928785e-01])},\n {'pred_logits': 1,\n  'probabilities': array([7.75048770e-04, 9.99191315e-01, 3.36365912e-05])},\n {'pred_logits': 0,\n  'probabilities': array([9.99954626e-01, 4.40758918e-05, 1.29762657e-06])}]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(preds)"
   ]
  }
 ]
}